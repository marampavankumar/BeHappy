{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531ad8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6b9b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Fine tuning language models (LLMs) involves adapting pre-trained models to specific tasks. The process typically begins by selecting a suitable pre-trained LLM, such as GPT or BERT. Then, task-specific training data is gathered or created. Next, the pre-trained model is fine tuned using this data by adjusting the model's parameters. Fine tuning involves a two-step process: pre-training and fine-tuning. During pre-training, the model is exposed to a large dataset and learns to predict the next word in a sentence. In fine-tuning, the model is further trained on a smaller dataset specific to the desired task. Fine tuning LLMs allows for better performance and adaptation to specific tasks, improving the accuracy and relevance of generated output. However, selecting the right hyperparameters, dataset size, and avoiding overfitting are key challenges in fine-tuning. Regularly monitoring the performance and fine-tuning iteration is important to achieve optimal results. Overall, fine tuning LLMs enables customization and refinement to suit the specific requirements of various natural language processing tasks.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key='')\n",
    "response = client.chat.completions.create(model=\"gpt-3.5-turbo\", \n",
    "                                          messages = [{\"role\":\"system\", \"content\": \n",
    "                                                       \"You are a helpful assistant\"},\n",
    "                                                        {\"role\":\"user\", \"content\": \n",
    "                                                         \"Give me a brief 10 line summary on fine tuning LLMs.\"}])\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e93d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
